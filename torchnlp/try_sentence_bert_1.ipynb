{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "try-sentence-bert-1.ipynb",
      "provenance": [],
      "mount_file_id": "19bMVJ6S-EvMbNdGHf-MMpDDs73TJl6BH",
      "authorship_tag": "ABX9TyMk2Cjf1UrNB1mUvWQjrsn8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/po3rin/python_playground/blob/master/torchnlp/try_sentence_bert_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FfPqBzXZUHV"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "\n",
        "!pip install tensorboard\n",
        "\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "!pip install fugashi ipadic"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scf8MGEUYkdj"
      },
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from transformers import BertJapaneseTokenizer\n",
        "from transformers.models.bert_japanese import tokenization_bert_japanese\n",
        "from transformers import BertModel, BertConfig\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwykMOW4ftQe"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXtWannzZmuV"
      },
      "source": [
        "tknz = BertJapaneseTokenizer(vocab_file=\"drive/MyDrive/resources/sentence-bert/vocab.txt\", do_lower_case=False, do_basic_tokenize=False)\n",
        "tknz.word_tokenizer = tokenization_bert_japanese.MecabTokenizer()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duzBI2vXbFnL"
      },
      "source": [
        "config = BertConfig.from_json_file(\"drive/MyDrive/resources/sentence-bert/config.json\")\n",
        "net = BertModel.from_pretrained(\"drive/MyDrive/resources/sentence-bert/pytorch_model.bin\", config=config).to(device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_poP_5E0cCw8"
      },
      "source": [
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlDMKwqhdRnN"
      },
      "source": [
        "ss = [\n",
        "      \"大学構内での喫煙は禁止です。\",\n",
        "      \"学校でタバコを吸うのはダメです。\",\n",
        "      \"今日は学校でタバコを買った。\"\n",
        "]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft9vPUv1iJkY",
        "outputId": "c78281a1-0bce-40d7-b029-7adf5d11b8d1"
      },
      "source": [
        "x = torch.LongTensor(ids).unsqueeze(0)\n",
        "a = net(x)\n",
        "\n",
        "bs, wc, dm = a[0].shape\n",
        "sum_vec = a[0][0][0]\n",
        "for i in range(1, wc):\n",
        "  sum_vec += a[0][0][i]\n",
        "mv = sum_vec /wc\n",
        "mv.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCCpxOJogjPo",
        "outputId": "f92e6904-d5a4-4a3f-a831-27605a832b77"
      },
      "source": [
        "xs1, xmsk = [], []\n",
        "for i in range(len(ss)):\n",
        "    tid = tknz.encode(ss[i])\n",
        "    xs1.append(torch.LongTensor(tid))\n",
        "    xmsk.append(torch.LongTensor([1] * len(tid)))\n",
        "xs1 = pad_sequence(xs1, batch_first=True).to(device)\n",
        "xmsk = pad_sequence(xmsk, batch_first=True).to(device)\n",
        "\n",
        "out = net(xs1,xmsk)\n",
        "sv = mean_pooling(out, xmsk)\n",
        "print(\"cos(s0,s1) = \", torch.cosine_similarity(sv[0], sv[1], dim=0).item())\n",
        "print(\"cos(s0,s2) = \", torch.cosine_similarity(sv[0], sv[2], dim=0).item())\n",
        "print(\"cos(s1,s2) = \", torch.cosine_similarity(sv[1], sv[2], dim=0).item())\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cos(s0,s1) =  0.5350393056869507\n",
            "cos(s0,s2) =  0.18858887255191803\n",
            "cos(s1,s2) =  0.6100609302520752\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}