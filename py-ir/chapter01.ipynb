{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章 文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 文字コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.1\n",
    "\n",
    "query = '京都'\n",
    "s1 = '清水寺は京都にある'\n",
    "s2 = '浅草寺は東京にある'\n",
    "print(query in s1)\n",
    "print(query in s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 1.2 #\n",
    "\n",
    "def check_query(filename, query):\n",
    "    with open(filename, 'r', encoding='UTF-8') as f:\n",
    "        s = f.read()\n",
    "        return query in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.3 #\n",
    "\n",
    "print(check_query('data/ch01/01.txt', '京都'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "京都 in data/ch01/01.txt...True\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xbd in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f2d3a2c7c5c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'data/ch01/%02d.txt'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} in {}...{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1b23127cbfa7>\u001b[0m in \u001b[0;36mcheck_query\u001b[0;34m(filename, query)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/c_2-HYPYMP9R/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xbd in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Listing 1.4 #\n",
    "\n",
    "query = '京都'\n",
    "file_list = ['data/ch01/%02d.txt' % x for x in (1, 2, 3, 4)]                    \n",
    "for f in file_list:\n",
    "    r = check_query(f, query)\n",
    "    print('{} in {}...{}'.format(query, f, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97]\n",
      "[97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.5 #\n",
    "\n",
    "print(list('a'.encode()))\n",
    "print(list('abc'.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181, 254]\n",
      "[139, 158]\n",
      "[228, 186, 172]\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.6 #\n",
    "\n",
    "print(list('京'.encode('EUC-JP')))\n",
    "print(list('京'.encode('SHIFT_JIS')))\n",
    "print(list('京'.encode('UTF-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'EUC-JP', 'confidence': 0.99, 'language': 'Japanese'}\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.7 #\n",
    "\n",
    "import chardet\n",
    "\n",
    "print(chardet.detect('明日，京都に行きます'.encode('EUC-JP')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.8 #\n",
    "\n",
    "print(chardet.detect('京'.encode('EUC-JP')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 1.9 #\n",
    "\n",
    "import chardet\n",
    "\n",
    "def get_string_from_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        d = f.read()\n",
    "        e = chardet.detect(d)['encoding']\n",
    "        # 推定できなかったときはUTF-8で\n",
    "        if e == None:\n",
    "            e = 'UTF-8'\n",
    "        return d.decode(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 1.10 #\n",
    "\n",
    "def check_encoding_and_query(filename, query):\n",
    "    s = get_string_from_file(filename)\n",
    "    return query in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "京都 in data/ch01/01.txt...True\n",
      "京都 in data/ch01/02.txt...False\n",
      "京都 in data/ch01/03.txt...True\n",
      "京都 in data/ch01/04.txt...True\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.11 #\n",
    "#\n",
    "# query = '京都'\n",
    "# file_list = ['data/ch01/%02d.txt' % x for x in (1, 2, 3, 4)]\n",
    "\n",
    "for f in file_list:\n",
    "    r = check_encoding_and_query(f, query)\n",
    "    print('{} in {}...{}'.format(query, f, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 文字Nグラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['情', '報', '検', '索']\n",
      "['情報', '報検', '検索']\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.12 #\n",
    "\n",
    "def get_ngram(string, N=1):\n",
    "    return [string[i:i+N] for i in range(len(string) - N + 1)]\n",
    "\n",
    "string = '情報検索'\n",
    "print(get_ngram(string, N=1))\n",
    "print(get_ngram(string, N=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 1.13 #\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_most_common_ngram(filename, N=1, k=1):\n",
    "    s = get_string_from_file(filename)\n",
    "    return Counter(get_ngram(s, N=N)).most_common(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('メロス', 76), ('った。', 53), ('ロスは', 47), ('のだ。', 37), ('。メロ', 33)]\n",
      "[('です。', 46), ('ている', 46), ('の写真', 34), ('した。', 33), ('のです', 32)]\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.14 #\n",
    "\n",
    "print(get_most_common_ngram('data/ch01/melos.txt', N=3, k=5))\n",
    "print(get_most_common_ngram('data/ch01/album.txt', N=3, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 正規表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "『つぶ餡』\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.15 #\n",
    "\n",
    "import re\n",
    "\n",
    "string = 'やっぱり『つぶ餡』が好き'\n",
    "pattern = '『.*』'\n",
    "result = re.search(pattern, string)\n",
    "print(result.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "つぶ餡\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.16 #\n",
    "\n",
    "string = 'やっぱり『つぶ餡』が好き'\n",
    "pattern = '『(.*)』'\n",
    "result = re.search(pattern, string)\n",
    "print(result.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "つぶ餡\n",
      "つぶ\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.17 #\n",
    "\n",
    "string = 'やっぱり『つぶ餡』が好き'\n",
    "pattern = '『((..).*)』'\n",
    "result = re.search(pattern, string)\n",
    "print(result.group(1))\n",
    "print(result.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "もちもち\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.18 #\n",
    "\n",
    "string = 'このぼたもちはとてももちもちしている'\n",
    "pattern = r'(..)\\1'\n",
    "result = re.search(pattern, string)\n",
    "print(result.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "つぶ餡』にするか『こし餡\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.19 #\n",
    "\n",
    "string = '『つぶ餡』にするか『こし餡』にするか'\n",
    "pattern = '『(.*)』'\n",
    "result = re.search(pattern, string)\n",
    "print(result.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "つぶ餡\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.20 #\n",
    "\n",
    "string = '『つぶ餡』にするか『こし餡』にするか'\n",
    "pattern = '『(.*?)』'\n",
    "result = re.search(pattern, string)\n",
    "print(result.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['つぶ餡', 'こし餡']\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.21 #\n",
    "\n",
    "string = '『つぶ餡』にするか『こし餡』にするか'\n",
    "pattern = '『(.*?)』'\n",
    "result = re.findall(pattern, string)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 1.22 #\n",
    "\n",
    "import re\n",
    "\n",
    "def get_snippet_from_file(filename, query, width=2):\n",
    "    s = get_string_from_file(filename)\n",
    "    p = '.{0,%d}%s.{0,%d}' % (width, query, width)                              \n",
    "    r = re.search(p, s)\n",
    "    if r:\n",
    "        return r.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ch01/01.txt 祇園祭は京都三大祭の一つ\n",
      "data/ch01/02.txt None\n",
      "data/ch01/03.txt 京都のお土産でお\n",
      "data/ch01/04.txt 築地市場は東京都江東区の豊洲\n"
     ]
    }
   ],
   "source": [
    "# Listing 1.23 #\n",
    "\n",
    "query = '京都'\n",
    "file_list = ['data/ch01/%02d.txt' % x for x in (1, 2, 3, 4)]                    \n",
    "for f in file_list:\n",
    "    print(f, get_snippet_from_file(f, query, width=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
