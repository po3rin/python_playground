{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "\n",
    "from es_client import ElasticClient\n",
    "from download import download\n",
    "\n",
    "# import ltr\n",
    "# import ltr.client as client\n",
    "# import ltr.index as index\n",
    "# import ltr.helpers.movies as helpers\n",
    "\n",
    "from judgement import Judgment, judgments_to_file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "corpus = 'http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "download([corpus], dest='data/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/tmdb.json already exists\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "client = ElasticClient()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Memoize:\n",
    "    \"\"\" Adapted from\n",
    "        https://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\"\"\"\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        self.memo = {}\n",
    "    def __call__(self, *args):\n",
    "        if not args in self.memo:\n",
    "            self.memo[args] = self.f(*args)\n",
    "        #Warning: You may wish to do a deepcopy here if returning objects\n",
    "        return self.memo[args]\n",
    "\n",
    "@Memoize\n",
    "def load_movies(json_path):\n",
    "    return json.load(open(json_path))\n",
    "\n",
    "def get_movie(tmdb_id, movies='data/tmdb.json'):\n",
    "    movies = load_movies(movies)\n",
    "    tmdb_id=str(tmdb_id)\n",
    "    return movies[tmdb_id]\n",
    "\n",
    "def noop(src_movie, base_doc):\n",
    "    return base_doc\n",
    "\n",
    "\n",
    "def indexable_movies(enrich=noop, movies='data/tmdb.json'):\n",
    "    \"\"\" Generates TMDB movies, similar to how ES Bulk indexing\n",
    "    uses a generator to generate bulk index/update actions\"\"\"\n",
    "    movies = load_movies(movies)\n",
    "    idx = 0\n",
    "    for movieId, tmdbMovie in movies.items():\n",
    "        try:\n",
    "            releaseDate = None\n",
    "            if 'release_date' in tmdbMovie and len(tmdbMovie['release_date']) > 0:\n",
    "                releaseDate = tmdbMovie['release_date']\n",
    "                releaseYear = releaseDate[0:4]\n",
    "\n",
    "            full_poster_path = ''\n",
    "            if 'poster_path' in tmdbMovie and tmdbMovie['poster_path'] is not None and len(tmdbMovie['poster_path']) > 0:\n",
    "                full_poster_path = 'https://image.tmdb.org/t/p/w185' + tmdbMovie['poster_path']\n",
    "\n",
    "            base_doc = {'id': movieId,\n",
    "                        'title': tmdbMovie['title'],\n",
    "                        'overview': tmdbMovie['overview'],\n",
    "                        'tagline': tmdbMovie['tagline'],\n",
    "                        'directors': [director['name'] for director in tmdbMovie['directors']],\n",
    "                        'cast': \" \".join([castMember['name'] for castMember in tmdbMovie['cast']]),\n",
    "                        'genres': [genre['name'] for genre in tmdbMovie['genres']],\n",
    "                        'release_date': releaseDate,\n",
    "                        'release_year': releaseYear,\n",
    "                        'poster_path': full_poster_path,\n",
    "                        'vote_average': float(tmdbMovie['vote_average']) if 'vote_average' in tmdbMovie else None,\n",
    "                        'vote_count': int(tmdbMovie['vote_count']) if 'vote_count' in tmdbMovie else 0,\n",
    "                      }\n",
    "            yield enrich(tmdbMovie, base_doc)\n",
    "            idx += 1\n",
    "        except KeyError as k: # Ignore any movies missing these attributes\n",
    "            continue"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def rebuild(client, index, doc_src, force = False):\n",
    "    \"\"\" Reload a configuration on disk for each search engine\n",
    "        (Solr a configset, Elasticsearch a json file)\n",
    "        and reindex\n",
    "    \"\"\"\n",
    "\n",
    "    if client.check_index_exists(index):\n",
    "        if (force):\n",
    "            client.delete_index(index)\n",
    "            client.create_index(index)\n",
    "            client.index_documents(index, doc_src=doc_src)\n",
    "        else:\n",
    "            print(\"Index {} already exists. Use `force = True` to delete and recreate\".format(index))\n",
    "            return None\n",
    "    else:\n",
    "        client.create_index(index)\n",
    "        client.index_documents(index, doc_src=doc_src)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "movies = indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/hiromu.nakamura/ghq/github.com/po3rin/python_playground/es-ltr/es_client.py:72: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.16/security-minimal-setup.html to enable security.\n",
      "  return self.es.indices.exists(index=index)\n",
      "/Users/hiromu.nakamura/ghq/github.com/po3rin/python_playground/es-ltr/es_client.py:75: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.16/security-minimal-setup.html to enable security.\n",
      "  resp = self.es.indices.delete(index=index, ignore=[400, 404])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleted index tmdb [Status: 200]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/hiromu.nakamura/ghq/github.com/po3rin/python_playground/es-ltr/es_client.py:84: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.16/security-minimal-setup.html to enable security.\n",
      "  resp = self.es.indices.create(index=index, body=settings)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created index tmdb [Status: 200]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/hiromu.nakamura/ghq/github.com/po3rin/python_playground/es-ltr/es_client.py:98: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.16/security-minimal-setup.html to enable security.\n",
      "  resp = elasticsearch.helpers.bulk(self.es, bulkDocs(doc_src), chunk_size=100)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Streaming Bulk index DONE tmdb [Status: 201]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/hiromu.nakamura/ghq/github.com/po3rin/python_playground/es-ltr/es_client.py:99: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.16/security-minimal-setup.html to enable security.\n",
      "  self.es.indices.refresh(index=index)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# wipes out any existing LTR models/feature sets in the tmdb index\n",
    "client.reset_ltr(index='tmdb')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed Default LTR feature store [Status: 200]\n",
      "Initialize Default LTR feature store [Status: 200]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "feature_set = {\n",
    "    \"featureset\": {\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"name\": \"release_year\",\n",
    "                \"params\": [],\n",
    "                \"template\": {\n",
    "                    \"function_score\": {\n",
    "                        \"field_value_factor\": {\n",
    "                            \"field\": \"release_year\",\n",
    "                            \"missing\": 2000\n",
    "                        },\n",
    "                        \"query\": { \"match_all\": {} }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "feature_set"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'featureset': {'features': [{'name': 'release_year',\n",
       "    'params': [],\n",
       "    'template': {'function_score': {'field_value_factor': {'field': 'release_year',\n",
       "       'missing': 2000},\n",
       "      'query': {'match_all': {}}}}}]}}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# pushes the feature set to the tmdb index's LTR store (a hidden index)\n",
    "client.create_featureset(index='tmdb', name='release', ftr_config=feature_set)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Create release feature set [Status: 201]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "実際のトレーニングセットを使用する前に、モデルの2つの例を試してみます。常に新しい映画を好むもの。そして、常に古い映画を好む別のもの。興味がある場合は、これを実行した後にclassic-training.txtとlatest-training.txtを操作して、トレーニングセットがどのように見えるかを確認できます。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def get_classic_rating(year):\n",
    "    if year > 2010:\n",
    "        return 0\n",
    "    elif year > 1990:\n",
    "        return 1\n",
    "    elif year > 1970:\n",
    "        return 2\n",
    "    elif year > 1950:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def get_latest_rating(year):\n",
    "    if year > 2010:\n",
    "        return 4\n",
    "    elif year > 1990:\n",
    "        return 3\n",
    "    elif year > 1970:\n",
    "        return 2\n",
    "    elif year > 1950:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def synthesize(\n",
    "    client,\n",
    "    featureSet='release',\n",
    "    latestTrainingSetOut='data/latest-training.txt',\n",
    "    classicTrainingSetOut='data/classic-training.txt'\n",
    "):\n",
    "    NO_ZERO = False\n",
    "\n",
    "    resp = client.log_query('tmdb', 'release', None)\n",
    "\n",
    "    # A classic film fan\n",
    "    judgments = []\n",
    "    print(\"Generating 'classic' biased judgments:\")\n",
    "    for hit in resp:\n",
    "        rating = get_classic_rating(hit['ltr_features'][0])\n",
    "\n",
    "        if rating == 0 and NO_ZERO:\n",
    "            continue\n",
    "\n",
    "        judgments.append(Judgment(qid=1,docId=hit['id'],grade=rating,features=hit['ltr_features'],keywords=''))\n",
    "\n",
    "\n",
    "    with open(classicTrainingSetOut, 'w') as out:\n",
    "        judgments_to_file(out, judgments)\n",
    "\n",
    "    # A current film fan\n",
    "    judgments = []\n",
    "    print(\"Generating 'recent' biased judgments:\")\n",
    "    for hit in resp:\n",
    "        rating = get_latest_rating(hit['ltr_features'][0])\n",
    "\n",
    "        if rating == 0 and NO_ZERO:\n",
    "            continue\n",
    "\n",
    "        judgments.append(Judgment(qid=1,docId=hit['id'],grade=rating,features=hit['ltr_features'],keywords=''))\n",
    "\n",
    "\n",
    "    with open(latestTrainingSetOut, 'w') as out:\n",
    "        judgments_to_file(out, judgments)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "synthesize(\n",
    "    client, \n",
    "    featureSet='release', # must match the name set in client.create_featureset(...)\n",
    "    classicTrainingSetOut='data/classic-training.txt',\n",
    "    latestTrainingSetOut='data/latest-training.txt'\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'_index': 'tmdb', '_type': '_doc', '_id': '374430', '_score': 0.0, '_source': {'id': '374430', 'title': 'Black Mirror: White Christmas', 'overview': \"This feature-length special consists of three interwoven stories. In a mysterious and remote snowy outpost, Matt and Potter share a Christmas meal, swapping creepy tales of their earlier lives in the outside world. Matt is a charismatic American trying to bring the reserved, secretive Potter out of his shell. But are both men who they appear to be? A woman gets thrust into a nightmarish world of 'smart' gadgetry. Plus a look at what would happen if you could 'block' people in real life.\", 'tagline': '', 'directors': ['Carl Tibbetts'], 'cast': 'Jon Hamm Rafe Spall Oona Chaplin Natalia Tena Janet Montgomery Rasmus Hardiker Dan Li Ken Drury Zahra Ahmadi Verity Marshall Ian Keir Attard', 'genres': ['Drama', 'Horror', 'Mystery', 'Science Fiction', 'Thriller', 'TV Movie'], 'release_date': '2014-12-16', 'release_year': '2014', 'poster_path': 'https://image.tmdb.org/t/p/w185/he609rnU3tiwBjRklKNa4n2jQSd.jpg', 'vote_average': 8.6, 'vote_count': 93, 'ltr_features': []}, 'matched_queries': ['logged_features']}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/hiromu.nakamura/ghq/github.com/po3rin/python_playground/es-ltr/es_client.py:153: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.16/security-minimal-setup.html to enable security.\n",
      "  resp = self.es.search(index=index, body=params)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'fields'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatureSet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelease\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# must match the name set in client.create_featureset(...)\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassicTrainingSetOut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/classic-training.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatestTrainingSetOut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/latest-training.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36msynthesize\u001b[0;34m(client, featureSet, latestTrainingSetOut, classicTrainingSetOut)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msynthesize\u001b[39m(\n\u001b[1;32m     26\u001b[0m     client,\n\u001b[1;32m     27\u001b[0m     featureSet\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m     latestTrainingSetOut\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/latest-training.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m     classicTrainingSetOut\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/classic-training.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m ):\n\u001b[1;32m     31\u001b[0m     NO_ZERO \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtmdb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelease\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# A classic film fan\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     judgments \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/ghq/github.com/po3rin/python_playground/es-ltr/es_client.py:162\u001b[0m, in \u001b[0;36mElasticClient.log_query\u001b[0;34m(self, index, featureset, ids, params)\u001b[0m\n\u001b[1;32m    158\u001b[0m hit[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mltr_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(hit)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfields\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_ltrlog\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mltr_features\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    163\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m feature:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fields'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('.venv': poetry)"
  },
  "interpreter": {
   "hash": "cc05f330fd211886cdb8b68fa6c8b24b37de2aa55e4fb20d8f171d24fd3b0ad4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}