{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "\n",
    "from es_client import ElasticClient\n",
    "from download import download\n",
    "\n",
    "# import ltr\n",
    "# import ltr.client as client\n",
    "# import ltr.index as index\n",
    "# import ltr.helpers.movies as helpers\n",
    "\n",
    "from judgement import Judgment, judgments_to_file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "corpus = 'http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "download([corpus], dest='data/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/tmdb.json already exists\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "client = ElasticClient()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Memoize:\n",
    "    \"\"\" Adapted from\n",
    "        https://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\"\"\"\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        self.memo = {}\n",
    "    def __call__(self, *args):\n",
    "        if not args in self.memo:\n",
    "            self.memo[args] = self.f(*args)\n",
    "        #Warning: You may wish to do a deepcopy here if returning objects\n",
    "        return self.memo[args]\n",
    "\n",
    "@Memoize\n",
    "def load_movies(json_path):\n",
    "    return json.load(open(json_path))\n",
    "\n",
    "def get_movie(tmdb_id, movies='data/tmdb.json'):\n",
    "    movies = load_movies(movies)\n",
    "    tmdb_id=str(tmdb_id)\n",
    "    return movies[tmdb_id]\n",
    "\n",
    "def noop(src_movie, base_doc):\n",
    "    return base_doc\n",
    "\n",
    "\n",
    "def indexable_movies(enrich=noop, movies='data/tmdb.json'):\n",
    "    \"\"\" Generates TMDB movies, similar to how ES Bulk indexing\n",
    "    uses a generator to generate bulk index/update actions\"\"\"\n",
    "    movies = load_movies(movies)\n",
    "    idx = 0\n",
    "    for movieId, tmdbMovie in movies.items():\n",
    "        try:\n",
    "            releaseDate = None\n",
    "            if 'release_date' in tmdbMovie and len(tmdbMovie['release_date']) > 0:\n",
    "                releaseDate = tmdbMovie['release_date']\n",
    "                releaseYear = releaseDate[0:4]\n",
    "\n",
    "            full_poster_path = ''\n",
    "            if 'poster_path' in tmdbMovie and tmdbMovie['poster_path'] is not None and len(tmdbMovie['poster_path']) > 0:\n",
    "                full_poster_path = 'https://image.tmdb.org/t/p/w185' + tmdbMovie['poster_path']\n",
    "\n",
    "            base_doc = {'id': movieId,\n",
    "                        'title': tmdbMovie['title'],\n",
    "                        'overview': tmdbMovie['overview'],\n",
    "                        'tagline': tmdbMovie['tagline'],\n",
    "                        'directors': [director['name'] for director in tmdbMovie['directors']],\n",
    "                        'cast': \" \".join([castMember['name'] for castMember in tmdbMovie['cast']]),\n",
    "                        'genres': [genre['name'] for genre in tmdbMovie['genres']],\n",
    "                        'release_date': releaseDate,\n",
    "                        'release_year': releaseYear,\n",
    "                        'poster_path': full_poster_path,\n",
    "                        'vote_average': float(tmdbMovie['vote_average']) if 'vote_average' in tmdbMovie else None,\n",
    "                        'vote_count': int(tmdbMovie['vote_count']) if 'vote_count' in tmdbMovie else 0,\n",
    "                      }\n",
    "            yield enrich(tmdbMovie, base_doc)\n",
    "            idx += 1\n",
    "        except KeyError as k: # Ignore any movies missing these attributes\n",
    "            continue"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def rebuild(client, index, doc_src, force = False):\n",
    "    \"\"\" Reload a configuration on disk for each search engine\n",
    "        (Solr a configset, Elasticsearch a json file)\n",
    "        and reindex\n",
    "    \"\"\"\n",
    "\n",
    "    if client.check_index_exists(index):\n",
    "        if (force):\n",
    "            client.delete_index(index)\n",
    "            client.create_index(index)\n",
    "            client.index_documents(index, doc_src=doc_src)\n",
    "        else:\n",
    "            print(\"Index {} already exists. Use `force = True` to delete and recreate\".format(index))\n",
    "            return None\n",
    "    else:\n",
    "        client.create_index(index)\n",
    "        client.index_documents(index, doc_src=doc_src)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "movies = indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index tmdb already exists. Use `force = True` to delete and recreate\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/hiromu.nakamura/ghq/github.com/po3rin/python_playground/.venv/lib/python3.9/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.16/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# wipes out any existing LTR models/feature sets in the tmdb index\n",
    "client.reset_ltr(index='tmdb')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed Default LTR feature store [Status: 200]\n",
      "Initialize Default LTR feature store [Status: 200]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "feature_set = {\n",
    "    \"featureset\": {\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"name\": \"release_year\",\n",
    "                \"params\": [],\n",
    "                \"template\": {\n",
    "                    \"function_score\": {\n",
    "                        \"field_value_factor\": {\n",
    "                            \"field\": \"release_year\",\n",
    "                            \"missing\": 2000\n",
    "                        },\n",
    "                        \"query\": { \"match_all\": {} }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "feature_set"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'featureset': {'features': [{'name': 'release_year',\n",
       "    'params': [],\n",
       "    'template': {'function_score': {'field_value_factor': {'field': 'release_year',\n",
       "       'missing': 2000},\n",
       "      'query': {'match_all': {}}}}}]}}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# pushes the feature set to the tmdb index's LTR store (a hidden index)\n",
    "client.create_featureset(index='tmdb', name='release', ftr_config=feature_set)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Create release feature set [Status: 201]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "実際のトレーニングセットを使用する前に、モデルの2つの例を試してみます。常に新しい映画を好むもの。そして、常に古い映画を好む別のもの。興味がある場合は、これを実行した後にclassic-training.txtとlatest-training.txtを操作して、トレーニングセットがどのように見えるかを確認できます。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def get_classic_rating(year):\n",
    "    if year > 2010:\n",
    "        return 0\n",
    "    elif year > 1990:\n",
    "        return 1\n",
    "    elif year > 1970:\n",
    "        return 2\n",
    "    elif year > 1950:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def get_latest_rating(year):\n",
    "    if year > 2010:\n",
    "        return 4\n",
    "    elif year > 1990:\n",
    "        return 3\n",
    "    elif year > 1970:\n",
    "        return 2\n",
    "    elif year > 1950:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def synthesize(\n",
    "    client,\n",
    "    featureSet='release',\n",
    "    latestTrainingSetOut='data/latest-training.txt',\n",
    "    classicTrainingSetOut='data/classic-training.txt'\n",
    "):\n",
    "    NO_ZERO = False\n",
    "\n",
    "    resp = client.log_query('tmdb', 'release', None)\n",
    "\n",
    "    # A classic film fan\n",
    "    judgments = []\n",
    "    print(\"Generating 'classic' biased judgments:\")\n",
    "    for hit in resp:\n",
    "        rating = get_classic_rating(hit['ltr_features'][0])\n",
    "\n",
    "        if rating == 0 and NO_ZERO:\n",
    "            continue\n",
    "\n",
    "        judgments.append(Judgment(qid=1,docId=hit['id'],grade=rating,features=hit['ltr_features'],keywords=''))\n",
    "\n",
    "\n",
    "    with open(classicTrainingSetOut, 'w') as out:\n",
    "        judgments_to_file(out, judgments)\n",
    "\n",
    "    # A current film fan\n",
    "    judgments = []\n",
    "    print(\"Generating 'recent' biased judgments:\")\n",
    "    for hit in resp:\n",
    "        rating = get_latest_rating(hit['ltr_features'][0])\n",
    "\n",
    "        if rating == 0 and NO_ZERO:\n",
    "            continue\n",
    "\n",
    "        judgments.append(Judgment(qid=1,docId=hit['id'],grade=rating,features=hit['ltr_features'],keywords=''))\n",
    "\n",
    "\n",
    "    with open(latestTrainingSetOut, 'w') as out:\n",
    "        judgments_to_file(out, judgments)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "synthesize(\n",
    "    client, \n",
    "    featureSet='release', # must match the name set in client.create_featureset(...)\n",
    "    classicTrainingSetOut='data/classic-training.txt',\n",
    "    latestTrainingSetOut='data/latest-training.txt'\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'query': {'bool': {'filter': [{'sltr': {'_name': 'logged_features', 'featureset': 'release', 'params': {}}}]}}, 'ext': {'ltr_log': {'log_specs': {'name': 'ltr_features', 'named_query': 'logged_features'}}}, 'size': 1000}\n",
      "Generating 'classic' biased judgments:\n",
      "Generating 'recent' biased judgments:\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('.venv': poetry)"
  },
  "interpreter": {
   "hash": "cc05f330fd211886cdb8b68fa6c8b24b37de2aa55e4fb20d8f171d24fd3b0ad4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}